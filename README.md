# NeuralNet

Artificial neural networks generally require large amounts of data to produce a model that can perform accurately when presented with new data. When using gradient descent to train the parameters of a neural network, we found that it does eventually converge to a reasonable local minimum and can get at least 96% accuracy on the testing data. However, by using stochastic gradient descent, a similar accuracy can be achieved while also needing less than 1/5th of the training time required by gradient descent.

## Plots
![Gradient Descent Plot](./gradient_descent_fig.png?raw=true)
![Gradient Descent Plot](./sgd_fig.png?raw=true)

## Training Statistics
*Stats found in gradient_descent_info.txt and sgd_info.txt files*
